{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "65638dd7-79e5-4b26-8e65-54bf81a58c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using 15 clusters\n",
      "✅ Clustering complete! Output saved to clustered_output.xlsx\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from collections import defaultdict\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"https://yash-ams-bot.openai.azure.com/\"\n",
    "openai.api_key = \"dd4c31d04b2c480685d34365c0d167c6\"\n",
    "openai.api_version = \"2023-07-01-preview\"  # Use the latest supported version\n",
    "OPENAI_API_VERSION = \"2024-05-01-preview\"\n",
    "# GPT_DEPLOYMENT_NAME = \"ams_gpt-35-turbo\"\n",
    "AZURE_DEPLOYMENT_NAME = \"gpt-4o\"\n",
    "EMBEDDING_MODEL_DEPLOYEMENT_NAME = \"text-embedding-ada-002\"\n",
    "\n",
    "\n",
    "# Read input data while keeping Number (ID) and combining multiple text columns if needed\n",
    "def read_excel(file_path, text_columns, id_column=\"Number\"):\n",
    "    df = pd.read_excel(file_path)\n",
    "    df = df[[id_column] + text_columns].dropna()  # Keep only relevant columns\n",
    "\n",
    "    # If multiple text columns, combine them into one\n",
    "    df[\"Combined_Text\"] = df[text_columns].astype(str).agg(\" \".join, axis=1)\n",
    "\n",
    "    return df[[id_column, \"Combined_Text\"]]\n",
    "\n",
    "# Get embeddings from Azure GPT\n",
    "def get_embeddings(texts):\n",
    "    response = openai.Embedding.create(\n",
    "        input=texts,\n",
    "        engine=EMBEDDING_MODEL_DEPLOYEMENT_NAME\n",
    "    )\n",
    "    return [data['embedding'] for data in response['data']]\n",
    "\n",
    "# Generate cluster names using LLM\n",
    "def generate_cluster_name(texts):\n",
    "    prompt = f\"These are some text samples from a cluster: {texts[:10]}. What would be a meaningful short name for this category? and only provide short names nothing else\"\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=AZURE_DEPLOYMENT_NAME,\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are an expert in categorizing text data.\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=20\n",
    "    )\n",
    "    \n",
    "    return response['choices'][0]['message']['content'].strip()\n",
    "\n",
    "# Automatically determine optimal number of clusters\n",
    "def find_optimal_clusters(embeddings, max_clusters=10):\n",
    "    scores = []\n",
    "    cluster_range = range(2, min(max_clusters, len(embeddings)))  # Avoid too many clusters for small data\n",
    "\n",
    "    for k in cluster_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        labels = kmeans.fit_predict(embeddings)\n",
    "        score = silhouette_score(embeddings, labels)\n",
    "        scores.append((k, score))\n",
    "\n",
    "    # Choose the number of clusters with the highest silhouette score\n",
    "    best_k = max(scores, key=lambda x: x[1])[0]\n",
    "    return best_k\n",
    "\n",
    "# Cluster text data while keeping IDs\n",
    "def cluster_texts(df, text_column=\"Combined_Text\", id_column=\"Number\", num_clusters=None, batch_size=50):\n",
    "    all_texts = []\n",
    "    all_ids = []\n",
    "    all_embeddings = []\n",
    "\n",
    "    # Process data in batches\n",
    "    for i in range(0, len(df), batch_size):\n",
    "        batch = df.iloc[i:i+batch_size]\n",
    "        batch_texts = batch[text_column].tolist()\n",
    "        batch_ids = batch[id_column].tolist()\n",
    "\n",
    "        embeddings = get_embeddings(batch_texts)  # Ensure this function is defined\n",
    "\n",
    "        all_texts.extend(batch_texts)\n",
    "        all_ids.extend(batch_ids)\n",
    "        all_embeddings.extend(embeddings)\n",
    "\n",
    "    # Convert embeddings to numpy array\n",
    "    all_embeddings = np.array(all_embeddings)\n",
    "\n",
    "    # Determine number of clusters automatically if not provided\n",
    "    if num_clusters is None:\n",
    "        computed_clusters = find_optimal_clusters(all_embeddings)  # Ensure this function is defined\n",
    "        num_clusters = max(5, computed_clusters)  # Ensure at least 2 clusters\n",
    "\n",
    "    print(f\"✅ Using {num_clusters} clusters\")\n",
    "\n",
    "    # Apply K-Means clustering\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init=10)\n",
    "    cluster_labels = kmeans.fit_predict(all_embeddings)\n",
    "\n",
    "    # Organize text into clusters while preserving IDs\n",
    "    clusters = defaultdict(list)\n",
    "    id_map = defaultdict(list)\n",
    "\n",
    "    for idx, label in enumerate(cluster_labels):\n",
    "        clusters[label].append(all_texts[idx])\n",
    "        id_map[label].append(all_ids[idx])\n",
    "\n",
    "    # Generate meaningful cluster names\n",
    "    cluster_names = {cluster_id: generate_cluster_name(texts) for cluster_id, texts in clusters.items()}\n",
    "\n",
    "    return clusters, cluster_names, id_map\n",
    "\n",
    "# Save clusters to Excel with IDs\n",
    "def save_clusters_to_excel(clusters, cluster_names, id_map, output_file):\n",
    "    data = []\n",
    "    for cluster_id, texts in clusters.items():\n",
    "        cluster_name = cluster_names.get(cluster_id, f\"Cluster {cluster_id}\")\n",
    "        for i, text in enumerate(texts):\n",
    "            data.append([id_map[cluster_id][i], cluster_name, text])\n",
    "\n",
    "    df = pd.DataFrame(data, columns=[\"Number\", \"Cluster Name\", \"Text\"])\n",
    "    df_main = pd.read_excel(input_file)\n",
    "    df = df_main.merge(df, on=\"Number\")\n",
    "    df = df.drop(['Text'], axis = 1)\n",
    "    df.to_excel(output_file, index=False)\n",
    "\n",
    "\n",
    "# Run the pipeline\n",
    "input_file = \"incident_15Oct24.xlsx\"\n",
    "output_file = \"clustered_output.xlsx\"\n",
    "id_column = \"Number\"\n",
    "\n",
    "# User can provide one or multiple text columns\n",
    "text_columns = [\"Short description\"]  # Example: Change to [\"Title\", \"Description\"] to combine multiple columns\n",
    "num_clusters = 15  # Set to an integer (e.g., 5) to specify clusters, or leave None for auto-detection\n",
    "\n",
    "df = read_excel(input_file, text_columns, id_column)\n",
    "clusters, cluster_names, id_map = cluster_texts(df, \"Combined_Text\", id_column, num_clusters)\n",
    "save_clusters_to_excel(clusters, cluster_names, id_map, output_file)\n",
    "\n",
    "print(f\"✅ Clustering complete! Output saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ab606098-31e1-4d40-bdb7-b457c902462b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openai\n",
      "Version: 0.28.0\n",
      "Summary: Python client library for the OpenAI API\n",
      "Home-page: https://github.com/openai/openai-python\n",
      "Author: OpenAI\n",
      "Author-email: support@openai.com\n",
      "License: \n",
      "Location: C:\\Users\\Nilay\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\n",
      "Requires: aiohttp, requests, tqdm\n",
      "Required-by: crewai, embedchain, guardrails-ai, instructor, langchain-openai, litellm, llama-index-agent-openai, llama-index-core, llama-index-legacy, mem0ai, pyautogen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~otebook (C:\\Users\\Nilay\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip show openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0eea8c-1e13-42f4-9161-3d8805f01f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name: openai\n",
    "Version: 0.28.0\n",
    "Summary: Python client library for the OpenAI API\n",
    "Home-page: https://github.com/openai/openai-python\n",
    "Author: OpenAI\n",
    "Author-email: support@openai.com\n",
    "License: \n",
    "Location: C:\\Users\\Nilay\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\n",
    "Requires: aiohttp, requests, tqdm\n",
    "Required-by: crewai, embedchain, guardrails-ai, instructor, langchain-openai, litellm, llama-index-agent-openai, llama-index-core, llama-index-legacy, mem0ai, pyautogen\n",
    "WARNING: Ignoring invalid distribution ~otebook (C:\\Users\\Nilay\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
